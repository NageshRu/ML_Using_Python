# -*- coding: utf-8 -*-
"""ELMo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F2N0uFL3f52blXhBNkMGdBpWiz_1gQ9q
"""

#Step 1:Importing all the packages whichever is do you want to include.

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import numpy as np
import spacy
from tqdm import tqdm
import re
import time
import pickle
pd.set_option('display.max_colwidth',200)

#Step 2:Reading the data and Inspecting.

train=pd.read_csv('gdrive/My Drive/train_2kmZucJ.csv')
test=pd.read_csv('gdrive/My Drive/test_oJQbWVk.csv')

train.shape,test.shape

train['label'].value_counts(normalize=True)
train.head()

#Step 3:Text cleaning and Preprocessing
#Removing url from the train dataset.

train['cleen_tweet']=train['tweet'].apply(lambda x:re.sub(r'http\S+', '',x))
test['cleen_tweet']=test['tweet'].apply(lambda x:re.sub(r'http\S+', '',x))

train

test

#So we are removing more non-related data from datasets
punctuation = '!"#$%&()*+-/:;<=>?@[\\]^_`{|}~'

train['cleen_tweet']=train['cleen_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))
test['cleen_tweet']=test['cleen_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))

train

test

#converting into lower case
train['cleen_tweet']=train['cleen_tweet'].str.lower()
test['cleen_tweet']=test['cleen_tweet'].str.lower()

train

test

#remove numbers fron cleen_tweet
train['cleen_tweet']=train['cleen_tweet'].str.replace('[0-9]',' ')
test['cleen_tweet']=test['cleen_tweet'].str.replace('[0-9]',' ')

#removing white spaces
train['cleen_tweet']=train['cleen_tweet'].apply(lambda x:' '.join(x.split()))
test['cleen_tweet']=test['cleen_tweet'].apply(lambda x:' '.join(x.split()))

train

test

#Identifinding various from of the same word.
nlp=spacy.load('en',disable=['parser','ner'])


def lemmatization(texts):
    output=[]
    for i in texts:
      s=[token.lemma_ for token in nlp(i)]
      output.append(' '.join(s))
    return output

train['cleen_tweet']=lemmatization(train['cleen_tweet'])
test['cleen_tweet']=lemmatization(test['cleen_tweet'])

train

test

train.sample(5)

import tensorflow_hub as hub
import tensorflow as tf

elmo = hub.Module("https://tfhub.dev/google/elmo/2", trainable=True)

#Random sentence
x = ["Roasted ants are a popular snack in Columbia"]

#embedding the sentence
embeddings=elmo(x,signature='default',as_dict=True)['elmo']
embeddings.shape

embeddings

def elmo_vectors(x):
  embeddings = elmo(x.tolist(), signature="default", as_dict=True)["elmo"]

  with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(tf.tables_initializer())
    # return average of ELMo features
    return sess.run(tf.reduce_mean(embeddings,1))

list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]
list_test = [test[i:i+100] for i in range(0,test.shape[0],100)]

elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]
elmo_test = [elmo_vectors(x['clean_tweet']) for x in list_test]

elmo_train_new = np.concatenate(list_train, axis = 0)
elmo_test_new = np.concatenate(list_test, axis = 0)

# save elmo_train_new
pickle_out = open("elmo_train_03032019.pickle","wb")
pickle.dump(elmo_train_new, pickle_out)
pickle_out.close()

# save elmo_test_new
pickle_out = open("elmo_test_03032019.pickle","wb")
pickle.dump(elmo_test_new, pickle_out)
pickle_out.close()

# load elmo_train_new
pickle_in = open("elmo_train_03032019.pickle", "rb")
elmo_train_new = pickle.load(pickle_in)

# load elmo_train_new
pickle_in = open("elmo_test_03032019.pickle", "rb")
elmo_test_new = pickle.load(pickle_in)

from sklearn.model_selection import train_test_split

xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, 
                                                  train['label'],  
                                                  random_state=42, 
                                                  test_size=0.2)

xtrain

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

lreg = LogisticRegression()
lreg.fit(xtrain, ytrain)



preds_valid = lreg.predict(xvalid)

f1_score(yvalid, preds_valid)

preds_test = lreg.predict(elmo_test_new)

pred_test